{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5513\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "path = \"C:/Users/bruno/OneDrive/Área de Trabalho/Teste/soja\" # replace with your folder path\n",
    "data_dir = pathlib.Path(path)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "\n",
    "#define some parameters to the loader\n",
    "batch_size = 32\n",
    "img_height = 227\n",
    "img_width = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: C:\\\\Users\\\\bruno\\\\OneDrive\\\\\\xc3\\x81rea de Trabalho\\\\Teste\\\\soja\\\\*\\\\*'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Creating a list of images\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m list_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*/*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m list_ds \u001b[38;5;241m=\u001b[39m list_ds\u001b[38;5;241m.\u001b[39mshuffle(image_count, reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Creating the class list\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1320\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[1;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[0;32m   1313\u001b[0m condition \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mgreater(array_ops\u001b[38;5;241m.\u001b[39mshape(matching_files)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   1314\u001b[0m                              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_not_empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1316\u001b[0m message \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files matched pattern: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1318\u001b[0m     string_ops\u001b[38;5;241m.\u001b[39mreduce_join(file_pattern, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1320\u001b[0m assert_not_empty \u001b[38;5;241m=\u001b[39m \u001b[43mcontrol_flow_assert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massert_not_empty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([assert_not_empty]):\n\u001b[0;32m   1323\u001b[0m   matching_files \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39midentity(matching_files)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\control_flow_assert.py:102\u001b[0m, in \u001b[0;36mAssert\u001b[1;34m(condition, data, summarize, name)\u001b[0m\n\u001b[0;32m    100\u001b[0m     xs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_n_to_tensor(data)\n\u001b[0;32m    101\u001b[0m     data_str \u001b[38;5;241m=\u001b[39m [_summarize_eager(x, summarize) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[0;32m    103\u001b[0m         node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    104\u001b[0m         op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be true. Summarized data: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    106\u001b[0m         (condition, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data_str)))\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssert\u001b[39m\u001b[38;5;124m\"\u001b[39m, [condition, data]) \u001b[38;5;28;01mas\u001b[39;00m name:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: C:\\\\Users\\\\bruno\\\\OneDrive\\\\\\xc3\\x81rea de Trabalho\\\\Teste\\\\soja\\\\*\\\\*'"
     ]
    }
   ],
   "source": [
    "#Creating a list of images\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "#Creating the class list\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 21\n",
      "Validation size: 0\n",
      "Test size: 0\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataset into train, test and validation sets\n",
    "train_size = int(0.7 * image_count)\n",
    "test_size = int(0.15 * image_count)\n",
    "\n",
    "train_ds = list_ds.take(train_size)\n",
    "test_ds = list_ds.skip(train_size)\n",
    "val_ds = test_ds.skip(test_size)\n",
    "test_ds = test_ds.take(test_size)\n",
    "\n",
    "print('Training size:', len(train_ds))\n",
    "print('Validation size:', len(val_ds))\n",
    "print('Test size:', len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  one_hot = parts[-2] == class_names\n",
    "  return tf.argmax(one_hot)\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # resize the image to the desired size\n",
    "  return tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)\n",
    "test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(x):\n",
    "  # branch with 1x1 conv\n",
    "  branch1x1 = layers.Conv2D(64, 1, activation='relu')(x)\n",
    "  branch3x3 = layers.Conv2D(64, 1, activation='relu')(x)\n",
    "  branch3x3 = layers.Conv2D(96, 3, padding='same', activation='relu')(branch3x3)\n",
    "  branch5x5 = layers.Conv2D(64, 1, activation='relu')(x)\n",
    "  branch5x5 = layers.Conv2D(96, 5, padding='same', activation='relu')(branch5x5)  \n",
    "  branchPol = layers.MaxPooling2D(3, strides=1, padding='same')(x)\n",
    "  branchPol = layers.Conv2D(96, 1, activation='relu')(branchPol)\n",
    "  output = layers.concatenate([branch1x1, branch3x3, branch5x5, branchPol], axis=3)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img = Input(shape=(227, 227, 3))  # Example input shape (224x224 RGB image)\n",
    "\n",
    "# Apply initial convolution and max pooling\n",
    "x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Apply the Inception module\n",
    "x = inception_module(x)\n",
    "\n",
    "# Apply additional convolution and pooling layers\n",
    "x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Flatten and add dense layers\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)  # Add dropout for regularization\n",
    "x = layers.Dense(len(class_names), activation='softmax')(x)  # Output layer with 10 classes (example)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_img, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 100ms/step - accuracy: 0.3559 - loss: 1.8084 - val_accuracy: 0.5345 - val_loss: 1.3212\n",
      "Epoch 2/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 108ms/step - accuracy: 0.5685 - loss: 1.2344 - val_accuracy: 0.5915 - val_loss: 1.1566\n",
      "Epoch 3/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 101ms/step - accuracy: 0.6548 - loss: 1.0032 - val_accuracy: 0.6254 - val_loss: 1.0781\n",
      "Epoch 4/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 102ms/step - accuracy: 0.7126 - loss: 0.8318 - val_accuracy: 0.6156 - val_loss: 1.1361\n",
      "Epoch 5/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 99ms/step - accuracy: 0.7626 - loss: 0.6871 - val_accuracy: 0.6306 - val_loss: 1.1814\n",
      "Epoch 6/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 99ms/step - accuracy: 0.8197 - loss: 0.5240 - val_accuracy: 0.6343 - val_loss: 1.2164\n",
      "Epoch 7/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 99ms/step - accuracy: 0.8658 - loss: 0.3916 - val_accuracy: 0.6289 - val_loss: 1.3353\n",
      "Epoch 8/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - accuracy: 0.9066 - loss: 0.2763 - val_accuracy: 0.6004 - val_loss: 1.6420\n",
      "Epoch 9/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 99ms/step - accuracy: 0.9353 - loss: 0.1941 - val_accuracy: 0.6176 - val_loss: 1.7527\n",
      "Epoch 10/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - accuracy: 0.9541 - loss: 0.1373 - val_accuracy: 0.6032 - val_loss: 2.0926\n",
      "Epoch 11/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 99ms/step - accuracy: 0.9644 - loss: 0.1038 - val_accuracy: 0.6093 - val_loss: 2.2565\n",
      "Epoch 12/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 99ms/step - accuracy: 0.9754 - loss: 0.0769 - val_accuracy: 0.6101 - val_loss: 2.3594\n",
      "Epoch 13/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - accuracy: 0.9803 - loss: 0.0609 - val_accuracy: 0.6078 - val_loss: 2.6009\n",
      "Epoch 14/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 99ms/step - accuracy: 0.9861 - loss: 0.0434 - val_accuracy: 0.6157 - val_loss: 2.8205\n",
      "Epoch 15/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - accuracy: 0.9878 - loss: 0.0377 - val_accuracy: 0.6174 - val_loss: 2.8756\n",
      "Epoch 16/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - accuracy: 0.9898 - loss: 0.0316 - val_accuracy: 0.6142 - val_loss: 3.1034\n",
      "Epoch 17/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 99ms/step - accuracy: 0.9909 - loss: 0.0307 - val_accuracy: 0.6135 - val_loss: 3.0940\n",
      "Epoch 18/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - accuracy: 0.9885 - loss: 0.0359 - val_accuracy: 0.6164 - val_loss: 3.1558\n",
      "Epoch 19/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 99ms/step - accuracy: 0.9893 - loss: 0.0343 - val_accuracy: 0.6161 - val_loss: 3.2810\n",
      "Epoch 20/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 104ms/step - accuracy: 0.9886 - loss: 0.0378 - val_accuracy: 0.6152 - val_loss: 3.2921\n",
      "Epoch 21/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 103ms/step - accuracy: 0.9886 - loss: 0.0352 - val_accuracy: 0.6135 - val_loss: 3.3260\n",
      "Epoch 22/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 102ms/step - accuracy: 0.9926 - loss: 0.0256 - val_accuracy: 0.6104 - val_loss: 3.5363\n",
      "Epoch 23/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 103ms/step - accuracy: 0.9925 - loss: 0.0220 - val_accuracy: 0.6099 - val_loss: 3.7268\n",
      "Epoch 24/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 101ms/step - accuracy: 0.9919 - loss: 0.0247 - val_accuracy: 0.6042 - val_loss: 3.8029\n",
      "Epoch 25/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 101ms/step - accuracy: 0.9911 - loss: 0.0280 - val_accuracy: 0.6031 - val_loss: 3.9629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25a8cf41590>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The filename must end in `.weights.h5`. Received: filepath=c:\\Users\\bruno\\OneDrive\\Área de Trabalho\\Teste\\model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m      6\u001b[0m \tjson_file\u001b[38;5;241m.\u001b[39mwrite(model_json)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_api.py:222\u001b[0m, in \u001b[0;36msave_weights\u001b[1;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.saving.save_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_weights\u001b[39m(model, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.h5`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m         )\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m         exists \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filepath)\n",
      "\u001b[1;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=c:\\Users\\bruno\\OneDrive\\Área de Trabalho\\Teste\\model.h5"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
