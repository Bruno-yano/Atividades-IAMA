{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7Nfk5jKFuvc/Cn2ReKqZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bruno-yano/Atividades-IAMA/blob/main/Soja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ThBuk4n8Ppfr"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: please generate code to load a folder in my google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "path = \"/content/drive/My Drive/Base_de_dados/Soja\" # replace with your folder path\n",
        "data_dir = pathlib.Path(path)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "\n",
        "#define some parameters to the loader\n",
        "batch_size = 32\n",
        "img_height = 227\n",
        "img_width = 227"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XO37etTUbHW",
        "outputId": "888697fd-b0cd-4b9b-d6f1-45185d1409af"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "5513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a list of images\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
        "#Creating the class list\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1SUOQ9gUukn",
        "outputId": "dd385cd1-4255-4033-d330-5fb3aa6df66e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Broken soybeans' 'Immature soybeans' 'Intact soybeans'\n",
            " 'Skin-damaged soybeans' 'Spotted soybeans']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset into train, test and validation sets\n",
        "train_size = int(0.7 * image_count)\n",
        "test_size = int(0.15 * image_count)\n",
        "\n",
        "train_ds = list_ds.take(train_size)\n",
        "test_ds = list_ds.skip(train_size)\n",
        "val_ds = test_ds.skip(test_size)\n",
        "test_ds = test_ds.take(test_size)\n",
        "\n",
        "print('Training size:', len(train_ds))\n",
        "print('Validation size:', len(val_ds))\n",
        "print('Test size:', len(test_ds))"
      ],
      "metadata": {
        "id": "et661HflVxRF",
        "outputId": "5ad5b367-628c-41e2-dfe0-9511ad26bcea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 3859\n",
            "Validation size: 828\n",
            "Test size: 826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  one_hot = parts[-2] == class_names\n",
        "  return tf.argmax(one_hot)\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n"
      ],
      "metadata": {
        "id": "-QmX_zrfWR_a"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))"
      ],
      "metadata": {
        "id": "mezFrmrmWsIB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)\n",
        "test_ds = configure_for_performance(test_ds)"
      ],
      "metadata": {
        "id": "bl3XYzrpW07D"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch,label_batch = next(iter(train_ds))\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "h-l9H-itW-A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model ="
      ],
      "metadata": {
        "id": "3eRLvbSBXKPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}